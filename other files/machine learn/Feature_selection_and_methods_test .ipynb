{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "###Feature selection  &  methods test                                                         ###\n",
    "###training & test dataset base on wangs:  functional_experimental_data_have_all_score_clean  ###\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CHASMplus  FATHMM_Cancer_score   ParsSNP  CanDrA_Score  REVEL_score  \\\n",
      "0         0.632                -4.05  0.379535     13.060500        0.947   \n",
      "1         0.515                -2.28  0.648592     13.050100        0.956   \n",
      "2         0.424                -1.95  0.344255     12.950300        0.461   \n",
      "3         0.221                -1.45  0.186465     12.528200        0.641   \n",
      "4         0.431                -1.95  0.201420     12.997700        0.614   \n",
      "5         0.648                -1.36  0.206577      4.719800        0.625   \n",
      "6         0.406                -1.86  0.122573      2.105400        0.636   \n",
      "7         0.304                -1.07  0.106733      1.760200        0.471   \n",
      "8         0.566                -3.69  0.111447      3.344800        0.977   \n",
      "9         0.458                -2.07  0.060360     10.519200        0.540   \n",
      "10        0.921                -2.72  0.183283     10.630000        0.906   \n",
      "11        0.042                 2.96  0.045029     -0.242150        0.546   \n",
      "12        0.052                 2.52  0.036955     -0.430980        0.526   \n",
      "13        0.483                -4.33  0.787388      4.688000        0.419   \n",
      "14        0.673                 0.82  0.212727      4.797000        0.533   \n",
      "15        0.078                 1.55  0.027214     -1.032500        0.042   \n",
      "16        0.340                 0.29  0.045281      3.974400        0.052   \n",
      "17        0.525                -1.22  0.106821      3.936700        0.436   \n",
      "18        0.005                 2.39  0.027372     -0.693650        0.047   \n",
      "19        0.221                 2.46  0.069730      3.272000        0.345   \n",
      "20        0.320                 1.37  0.060213      3.291000        0.455   \n",
      "21        0.131                -0.57  0.027840     -0.231570        0.234   \n",
      "22        0.068                -0.66  0.027407     -0.107950        0.283   \n",
      "23        0.050                -0.56  0.027153     -0.188230        0.058   \n",
      "24        0.462                -3.20  0.342042      1.403200        0.363   \n",
      "25        0.316                -3.14  0.679952      1.441000        0.342   \n",
      "26        0.510                 1.33  0.303573      1.581800        0.417   \n",
      "27        0.037                 3.54  0.026870      0.020655        0.749   \n",
      "28        0.132                 1.50  0.027803     -0.341210        0.153   \n",
      "29        0.603                 0.92  0.193436      2.347300        0.374   \n",
      "...         ...                  ...       ...           ...          ...   \n",
      "4759      0.260                 0.93  0.028238     -0.408810        0.563   \n",
      "4760      0.200                 0.67  0.028014     -0.446900        0.335   \n",
      "4761      0.118                 1.95  0.027757     -0.396420        0.116   \n",
      "4762      0.250                 3.14  0.028301     -0.450230        0.432   \n",
      "4763      0.113                 3.30  0.027307     -0.459280        0.015   \n",
      "4764      0.105                 3.12  0.028171     -0.511400        0.145   \n",
      "4765      0.121                 3.12  0.027730     -0.459300        0.075   \n",
      "4766      0.135                 3.13  0.028122     -0.451100        0.214   \n",
      "4767      0.072                 3.29  0.027897     -0.490820        0.142   \n",
      "4768      0.135                 3.16  0.027937     -0.499790        0.164   \n",
      "4769      0.158                 3.32  0.027685     -0.507090        0.050   \n",
      "4770      0.064                 3.30  0.027477     -0.465750        0.036   \n",
      "4771      0.145                 3.19  0.028323     -0.510790        0.246   \n",
      "4772      0.114                 3.17  0.028141     -0.555240        0.205   \n",
      "4773      0.062                 3.32  0.028420     -0.486970        0.339   \n",
      "4774      0.078                 3.25  0.027388     -0.525730        0.093   \n",
      "4775      0.074                 3.12  0.027153     -0.429180        0.022   \n",
      "4776      0.172                 3.15  0.028272     -0.464470        0.254   \n",
      "4777      0.165                 3.00  0.028347     -0.497450        0.302   \n",
      "4778      0.115                 3.13  0.027326     -0.551100        0.029   \n",
      "4779      0.110                 3.16  0.027768     -0.471610        0.050   \n",
      "4780      0.214                 3.12  0.028269     -0.388280        0.398   \n",
      "4781      0.231                 3.22  0.028225     -0.361140        0.365   \n",
      "4782      0.190                 2.88  0.027936     -0.483860        0.274   \n",
      "4783      0.096                 3.17  0.027330     -0.542150        0.025   \n",
      "4784      0.081                 3.17  0.027368     -0.550770        0.015   \n",
      "4785      0.072                 3.21  0.027220     -0.383360        0.073   \n",
      "4786      0.102                 3.18  0.027754     -0.583090        0.074   \n",
      "4787      0.071                 3.16  0.027423     -0.652710        0.039   \n",
      "4788      0.084                 3.30  0.027386     -0.684400        0.011   \n",
      "\n",
      "      SIFT_score  LRT_score  MutationAssessor_score  DANN_score  \n",
      "0          0.001   0.000015                   4.005    0.995254  \n",
      "1          0.000   0.000000                   1.655    0.998601  \n",
      "2          0.042   0.000000                   0.325    0.998171  \n",
      "3          0.000   0.000000                   2.660    0.998732  \n",
      "4          0.004   0.000000                   1.030    0.999222  \n",
      "5          0.002   0.000000                   2.650    0.998143  \n",
      "6          0.002   0.000000                  -0.440    0.998111  \n",
      "7          0.187   0.000055                   2.670    0.977118  \n",
      "8          0.000   0.000000                   3.960    0.997786  \n",
      "9          0.069   0.000000                   1.260    0.995675  \n",
      "10         0.000   0.000000                   4.065    0.997692  \n",
      "11         0.038   0.000000                   2.845    0.996781  \n",
      "12         0.033   0.000000                   2.330    0.998125  \n",
      "13         0.002   0.000000                   2.015    0.994295  \n",
      "14         0.005   0.000000                   2.045    0.995166  \n",
      "15         0.361   0.946608                   1.245    0.951017  \n",
      "16         0.051   0.000002                   1.040    0.998312  \n",
      "17         0.012   0.000000                   0.850    0.928938  \n",
      "18         0.877   0.000588                  -0.425    0.715097  \n",
      "19         0.221   0.000000                   0.170    0.971858  \n",
      "20         0.031   0.000054                   1.875    0.997955  \n",
      "21         0.183   0.000000                   1.545    0.998474  \n",
      "22         0.031   0.000514                   0.000    0.997046  \n",
      "23         0.055   0.538562                   0.345    0.987584  \n",
      "24         0.029   0.000009                   3.680    0.996707  \n",
      "25         0.130   0.000063                   2.865    0.971205  \n",
      "26         0.000   0.000754                   3.920    0.990965  \n",
      "27         0.001   0.000000                   3.205    0.999345  \n",
      "28         0.180   0.000666                   0.390    0.990351  \n",
      "29         0.001   0.000000                   0.910    0.994463  \n",
      "...          ...        ...                     ...         ...  \n",
      "4759       0.000   0.000000                   2.900    0.984404  \n",
      "4760       0.001   0.000001                   2.900    0.997291  \n",
      "4761       0.079   0.002908                   2.470    0.964935  \n",
      "4762       0.071   0.000000                   2.830    0.992050  \n",
      "4763       0.604   0.363543                   0.055    0.682710  \n",
      "4764       0.028   0.000000                   2.595    0.980616  \n",
      "4765       0.048   0.000007                   2.425    0.933484  \n",
      "4766       0.112   0.000007                   2.080    0.966029  \n",
      "4767       0.467   0.000007                   2.080    0.929614  \n",
      "4768       0.140   0.002052                   1.245    0.949892  \n",
      "4769       0.530   0.004190                   0.165    0.822018  \n",
      "4770       0.450   0.004190                   0.570    0.870045  \n",
      "4771       0.399   0.000000                   1.810    0.993309  \n",
      "4772       0.561   0.000110                   1.700    0.835146  \n",
      "4773       0.473   0.000110                   2.390    0.970403  \n",
      "4774       0.148   0.000015                   0.915    0.868273  \n",
      "4775       0.693   0.022386                   0.475    0.849472  \n",
      "4776       0.014   0.000000                   2.700    0.995721  \n",
      "4777       0.046   0.000000                   2.430    0.998877  \n",
      "4778       0.329   0.001522                   0.690    0.978949  \n",
      "4779       0.151   0.001522                   2.135    0.998595  \n",
      "4780       0.013   0.000000                   2.745    0.993096  \n",
      "4781       0.048   0.000000                   2.745    0.978204  \n",
      "4782       0.001   0.295003                   2.560    0.998437  \n",
      "4783       0.149   0.192169                   1.320    0.983341  \n",
      "4784       0.441   0.014852                   0.840    0.978027  \n",
      "4785       0.015   0.000068                   2.295    0.987945  \n",
      "4786       0.020   0.000032                   1.685    0.997788  \n",
      "4787       0.012   0.962898                  -0.345    0.989904  \n",
      "4788       0.123   0.962898                  -0.345    0.910280  \n",
      "\n",
      "[4789 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#import & dataread\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm,datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pandas import Series,DataFrame\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "data = pd.read_csv('functional_experimental_data_have_all_score_clean.tsv', sep='\\t')\n",
    "#print(data.head())\n",
    "baseset = DataFrame(data)\n",
    "scorename = ['CHASMplus', 'FATHMM_Cancer_score', 'ParsSNP', 'CanDrA_Score', 'REVEL_score','SIFT_score','LRT_score','MutationAssessor_score','DANN_score']\n",
    "f_score = baseset.loc[:,['CHASMplus', 'FATHMM_Cancer_score', 'ParsSNP', 'CanDrA_Score', 'REVEL_score','SIFT_score','LRT_score','MutationAssessor_score','DANN_score']]\n",
    "label = baseset['label']\n",
    "print(f_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            ####multiple imputation & simple imputation###\n",
    "#####  SimpleImputer by  Scikit-learn Preprocessing data\n",
    "\n",
    "#functional_experimental_data_have_all_score_clean need not imputation because not Missing values\n",
    "#the function for ohter works\n",
    "\n",
    "#functional_experimental_data_have_all_score_clean_missing.tsv has missing values .it is only a test!\n",
    "import numpy as np\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from statsmodels.imputation import mice\n",
    "\n",
    "def new_missing_tab(tab):   #new a tab with random missing value\n",
    "    data = pd.read_csv(tab, sep='\\t')\n",
    "    f1 = DataFrame(data)\n",
    "    scorename = ['CHASMplus', 'FATHMM_Cancer_score', 'ParsSNP', 'CanDrA_Score', 'REVEL_score','SIFT_score','LRT_score','MutationAssessor_score','DANN_score']\n",
    "    f2 = f1.loc[:,['CHASMplus', 'FATHMM_Cancer_score', 'ParsSNP', 'CanDrA_Score', 'REVEL_score','SIFT_score','LRT_score','MutationAssessor_score','DANN_score','label']]\n",
    "    for index, row in f2.iterrows():\n",
    "        if random.randint(0,9) == 1:\n",
    "            f2.iloc[index,0] = \"NaN\"\n",
    "    f2.to_csv('functional_experimental_data_have_all_score_clean_missing.csv',index=0)\n",
    "            \n",
    "def simple_imputer(miss_tab,strategy):\n",
    "    data = pd.read_csv(miss_tab, sep=',')\n",
    "    f2 = open(\"imp_test.txt\",'w')\n",
    "    f1 = DataFrame(data)\n",
    "    column_name = ['CHASMplus', 'FATHMM_Cancer_score', 'ParsSNP', 'CanDrA_Score', 'REVEL_score','SIFT_score','LRT_score','MutationAssessor_score','DANN_score','label']\n",
    "    for i in column_name:\n",
    "        f2.write(str(i))\n",
    "        f2.write(\"\t\")\n",
    "    f2.write('\\n')    \n",
    "        \n",
    "    chs = f1['CHASMplus']\n",
    "    #print(chs[0:100])\n",
    "    imp = SimpleImputer(missing_values = np.nan, strategy = strategy)\n",
    "    imp.fit(f1)\n",
    "    result = imp.transform(f1)\n",
    "    \n",
    "    \n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            f2.write(str(j))\n",
    "            f2.write(\"\t\")\n",
    "        f2.write('\\n')\n",
    "    \n",
    "           \n",
    "\n",
    "        \n",
    "    #print(f2)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "tab = 'functional_experimental_data_have_all_score_clean.tsv'\n",
    "\n",
    "#####################new a tab with random missing value################################\n",
    "#new_missing_tab(tab)  \n",
    "########################################################################################\n",
    "\n",
    "miss_table = 'functional_experimental_data_have_all_score_clean_missing.csv'\n",
    "\n",
    "strategy = 'mean'  # strategy can be mean, median or most frequent\n",
    "#simple_imputer(miss_tab,strategy)\n",
    "####################################################\n",
    "#multiple imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MutPred_score', 'FATHMM_score', 'MetaLR_score', 'REVEL_score', 'MetaSVM_score', 'M-CAP_score', 'phyloP100way_vertebrate', 'MutationAssessor_score', 'GERP++_RS', 'VEST3_score', 'PROVEAN_score', 'GM12878_fitCons_score', 'H1-hESC_fitCons_score', 'phyloP20way_mammalian', 'phastCons20way_mammalian'] 15\n"
     ]
    }
   ],
   "source": [
    "f = open('feature_importance.txt','r')\n",
    "l = f.readline()\n",
    "l = f.readline()\n",
    "imp = []\n",
    "while l:\n",
    "    a = l.split('  ')\n",
    "    imp.append(a[0])\n",
    "    l = f.readline()\n",
    "target = [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 14, 15, 19, 21, 26]\n",
    "methods_list = []\n",
    "for n in target:\n",
    "    methods_list.append(imp[n])\n",
    "print(methods_list,len(methods_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                            ####model value & data normalization###\n",
    "#auc roc\n",
    "def roc(label,score1,score2):\n",
    "    fpr1, tpr1, _ = roc_curve(label, score1)\n",
    "    roc_auc1 = auc(fpr1, tpr1)\n",
    "    fpr2, tpr2, _ = roc_curve(label, score2)\n",
    "    roc_auc2 = auc(fpr2, tpr2)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr1, tpr1, color='navy', lw=2, label='chasm+ ROC curve (area = %0.2f)' % roc_auc1)\n",
    "    plt.plot(fpr2, tpr2, color='red', lw=2, label='new score ROC curve (area = %0.2f)' % roc_auc2)\n",
    "    #plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1])\n",
    "    plt.ylim([0, 1.01])\n",
    "    plt.xlabel('False Positive Rate') \n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('chasm+ vs chasm+ impute missing value')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "def mvp_score(arr,label):\n",
    "    CHASMplus_mvp_score = 0.884424308588064\n",
    "\n",
    "    score = metrics.roc_auc_score(label,arr)\n",
    "    return score\n",
    "def z_score(list1,n):\n",
    "    z_list = []\n",
    "    z_list = pd.Series(z_list)\n",
    "    for i in range(n):\n",
    "        a = list1.iloc[:, [i]]\n",
    "        a_mean = a.mean(axis=0)  \n",
    "          \n",
    "        a_std = a.std(axis=0)  \n",
    "        \n",
    "        a1 = (a-a_mean)/a_std\n",
    "        \n",
    "        \n",
    "        z_list = pd.concat([z_list,a1],axis=1)\n",
    "    #print(z_list)\n",
    "    return z_list\n",
    "def normal(list1,n):\n",
    "    nor_list = []\n",
    "    nor_list = pd.Series(nor_list)\n",
    "    for i in range(n):\n",
    "        a = list1.iloc[:, [i]]\n",
    "        maxi = a.max(axis=0)\n",
    "        mini = a.min(axis=0)\n",
    "        a1 = (a - mini) / (maxi - mini)\n",
    "        nor_list = pd.concat([nor_list,a1],axis=1)\n",
    "    return nor_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
